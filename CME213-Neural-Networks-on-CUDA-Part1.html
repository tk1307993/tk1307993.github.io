<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">










  <meta name="baidu-site-verification" content="YFxkzhwIVx">







  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Algorithm,CUDA,Machine Learning,MPI,">





  <link rel="alternate" href="/atom.xml" title="留学生CS编程作业代写" type="application/atom+xml">






<meta name="description" content="结合了神经网络的高级的CUDA，用GPU进行NeuralNetwork的算法编写进行数字识别。核心算法部分框架都已提供，需要实现的主要是相关数据结构在GPU中的申请和释放。">
<meta name="keywords" content="Algorithm,CUDA,Machine Learning,MPI">
<meta property="og:type" content="article">
<meta property="og:title" content="CUDA代写：CME213-Neural-Networks-on-CUDA-Part1">
<meta property="og:url" content="https://tk1307993.coding.me/CME213-Neural-Networks-on-CUDA-Part1.html">
<meta property="og:site_name" content="留学生CS编程作业代写">
<meta property="og:description" content="结合了神经网络的高级的CUDA，用GPU进行NeuralNetwork的算法编写进行数字识别。核心算法部分框架都已提供，需要实现的主要是相关数据结构在GPU中的申请和释放。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2019-04-27T03:32:16.946Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CUDA代写：CME213-Neural-Networks-on-CUDA-Part1">
<meta name="twitter:description" content="结合了神经网络的高级的CUDA，用GPU进行NeuralNetwork的算法编写进行数字识别。核心算法部分框架都已提供，需要实现的主要是相关数据结构在GPU中的申请和释放。">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://tk1307993.coding.me/CME213-Neural-Networks-on-CUDA-Part1.html">





  <title>CUDA代写：CME213-Neural-Networks-on-CUDA-Part1 | 留学生CS编程作业代写</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">留学生CS编程作业代写</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">专业 高效 原创 QQ：1926742804</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-首页">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-分类">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-标签">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-归档">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-关于我">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于我
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tk1307993.coding.me/CME213-Neural-Networks-on-CUDA-Part1.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CPlusPlus小砖家">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="留学生CS编程作业代写">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">CUDA代写：CME213-Neural-Networks-on-CUDA-Part1</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-27T11:29:05+08:00">
                2019-04-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CUDA/" itemprop="url" rel="index">
                    <span itemprop="name">CUDA</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          
              <div class="post-description">
                  结合了神经网络的高级的CUDA，用GPU进行NeuralNetwork的算法编写进行数字识别。核心算法部分框架都已提供，需要实现的主要是相关数据结构在GPU中的申请和释放。
              </div>
          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>In this project, you will implement a neural network using CUDA to identify digits from handwritten images (a specific case of image classification problem). Neural networks are widely used in machine learning problems, specifically in the domains of image processing, computer vision and natural language processing. Recently, there has been a lot of excitement regarding deep learning, which basically uses more advanced variants of the simpler neural network (NN) we cover here. Therefore, being able to train large neural networks efficiently is important and is the goal of this project.</p>
<p>The main purpose of this Part I is to introduce you to the project and give you a picture of what needs to be done. Details of the starter code, submission instructions and full details of the grading steps will be handed out in Part II.</p>
<h3 id="Data-and-Notation"><a href="#Data-and-Notation" class="headerlink" title="Data and Notation"></a>Data and Notation</h3><p>We will be using the MNIST dataset, which consists of greyscale 28 × 28 pixel images of handwritten digits from 0 to 9.</p>
<p>The dataset is divided into two parts — 60,000 training data and 10,000 test data. We will use the training data to learn the parameters of our neural network (described later), and the test data to measure the performance of the learned network.</p>
<p>In the training process, one issue will be overfitting on the training data. To avoid this, a standard practice is to perform a cross-validation — a technique to measure how the model will generalize on an independent dataset. Cross-validation is carried out by further dividing the training data into two sets - a training set and a validation set. The validation set is a small portion (usually 10%) of the training dataset. We then perform the training on the training set (excluding the validation set) and evaluate our model on the validation set. There are different types of cross-validation, and we will only do a single holdout for validation because of computational issues. We use insights from this validation to improve our model.</p>
<p>The goal of the test set is to perform a final evaluation of our model on the unseen data. It is not meant to be used to in the training process.</p>
<h3 id="Neural-Networks"><a href="#Neural-Networks" class="headerlink" title="Neural Networks"></a>Neural Networks</h3><h4 id="Neurons"><a href="#Neurons" class="headerlink" title="Neurons"></a>Neurons</h4><p>To describe neural networks, we will begin by describing the simplest possible neural network, one which comprises a single “neuron.”</p>
<p>This is a good time for us to discuss the calculation of the derivative of the sigmoid function with respect to its input, since we are going to use it significantly in the following sections.</p>
<p>The neuron performs a linear transform on the input and then applies a non-linear transformation (sigmoid, in this case).<br>When a single neuron is used, we are limited to a binary classification. Take the example of a cancer tumor. We may build a neural network that takes as input the size of the tumor, its location, and the length of time it has been there. Based on these three pieces of information, the network needs to determine whether the tumor is benign or malignant. This is a true/false type of determination. In our previous model using the sigmoid function, we can interpret the output of the network.</p>
<p>Our task is therefore to learn the parameters of the network W and b so that it achieves the best accuracy or precision on the test set.</p>
<p>In the project we need to extend this concept to multiple classes. Instead of a simple true/false output, we need to decide which digits from 0 to 9 is shown on the input image. This requires a full neural network.</p>
<h4 id="Fully-connected-neural-network"><a href="#Fully-connected-neural-network" class="headerlink" title="Fully-connected neural network"></a>Fully-connected neural network</h4><p>Figure 4 shows a fully-connected neural network with 1 input layer, 1 hidden layer, and 1 output layer. We call such a network to be a two-layered neural network (ignoring the input layer as it is trivially present)</p>
<p>In our problem, we are trying to determine the digit associated with each image. We will call this digit the “label” associated with the image (using the neural network terminology). The total number of labels is denoted C. In our case C = 10, since we are trying to determine digits 0 to 9.</p>
<p>The last layer is special. This is the output of our network. In the project, we have C = 10 output nodes. Each node represent a possible digit. We will see later on how the output vector y can be interpreted to determine the digit that is guessed by the network for a given image.</p>
<h4 id="Feed-forward"><a href="#Feed-forward" class="headerlink" title="Feed-forward"></a>Feed-forward</h4><p>The nice thing about neural networks is that they are highly modular. Layer L[i] does not need to know whether its input is the input layer itself or the output of L[i−1]. L[i] computes its activations</p>
<h4 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h4><p>Recall that our objective is to learn the parameters of the neural network such that it gets the best accuracy on a set of data points, which we call the dev set. Let y be the one-hot vector denoting the class of the input, i.e., y[c] = 1 if c is the correct label, 0, otherwise. We want P (label = c|x) to be the highest.</p>
<p>Without going into the mathematical details, we will use the following general expression to determine the error of our neural network.</p>
<p>The above cost measures the error or our “dissatisfaction” with the output of the network. The more certain the network is about the correct label (high P (y = c|x)), the lower our cost will be.</p>
<p>Clearly, we should choose the parameters that minimize this cost. This is an optimization problem, and is usually solved using the method of Gradient Descent (described below).</p>
<p>Our neural network applies a non-linear function to the input because of the sigmoid and softmax functions. However, if we make W very small, the network becomes nearly linear because T is itself very small. To optimize the neural network, we often add a penalization term for the magnitude of W in order to control the non-linearity of the network. There is no rigorous justification for this penalization. It is found to work well in practice and is easy to use. With the penalization term.</p>
<h4 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h4><p>Gradient Descent is an iterative algorithm for finding local minima of a function.</p>
<p>In practice, we often do not compute J using all the input images. Instead, we subdivide the input into mini-batches containing M images. We process one mini-batch at a time. For each mini-batch, we calculate J, and update the network coefficients. Then, process the next batch, until all images are processed. See Listing 5 for the pseudo-code. In the code, an epoch (in the machine learning lingo) is an iteration over the entire data set of N images.</p>
<p>This approach usually leads to faster convergence because we update the network coefficients more often and are able to learn faster.</p>
<h4 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h4><p>Backpropagation is the process of updating the neural network coefficients. This involves computing the gradient of multi-variable functions using the chain rule.</p>
<h3 id="Outline-of-parallelization-strategies-for-CUDA-and-MPI"><a href="#Outline-of-parallelization-strategies-for-CUDA-and-MPI" class="headerlink" title="Outline of parallelization strategies for CUDA and MPI"></a>Outline of parallelization strategies for CUDA and MPI</h3><ul>
<li>GEMM CUDA implementation: A GEMM operation can be expressed as D = a <em> A </em> B + b * C. Some BLAS libraries perform in-place computation that saves the result D in the memory space of C, as cuBLAS does. This is possible if C is no longer used after the computation.</li>
<li>We first outline the basic implementation (“Algorithm 1”). The simplest implementation is to have one thread for each element in the result D. Each thread reads the required row of A, column of B, and an element of C to compute the output element in D.<br>For Algorithm 2, try to think of a better implementation. For example, use a blocking algorithm and take advantage of the shared memory. One approach is to have each thread block (e.g., a block of 32<em>32 threads) compute a sub-matrix (of size 32</em>32) in the output matrix. Blocks from matrices A and B can be loaded into shared memory, with each thread reading one element of each sub-matrix.</li>
<li>Each thread then updates its entry in the sub-matrix of D. A loop is used to multiply all the required entries in A and B. For an even more optimized and a possible “A+ grade” implementation, please refer to section 5.</li>
<li>We intentionally do not explain the details of these algorithms. It’s for you to fill the blanks and perhaps come up with better ideas!</li>
<li>MPI implementation: For each batch of images, you should subdivide the input images into smaller image batches and use MPI communication methods to distribute the input data and Neural Network parameters among MPI nodes, and perform GEMM and other computations in parallel. The resulting network coefficient updates should be reduced and sent to all nodes.</li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Algorithm/" rel="tag"># Algorithm</a>
          
            <a href="/tags/CUDA/" rel="tag"># CUDA</a>
          
            <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          
            <a href="/tags/MPI/" rel="tag"># MPI</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/CS125-Course-Scheduler.html" rel="next" title="Java代写：CS125-Course-Scheduler">
                <i class="fa fa-chevron-left"></i> Java代写：CS125-Course-Scheduler
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/CME213-Neural-Networks-on-CUDA-Part2.html" rel="prev" title="CUDA代写：CME213-Neural-Networks-on-CUDA-Part2">
                CUDA代写：CME213-Neural-Networks-on-CUDA-Part2 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.gif" alt="CPlusPlus小砖家">
            
              <p class="site-author-name" itemprop="name">CPlusPlus小砖家</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">269</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">23</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">54</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="mailto:1926742804@qq.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-and-Notation"><span class="nav-number">2.</span> <span class="nav-text">Data and Notation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Neural-Networks"><span class="nav-number">3.</span> <span class="nav-text">Neural Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Neurons"><span class="nav-number">3.1.</span> <span class="nav-text">Neurons</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Fully-connected-neural-network"><span class="nav-number">3.2.</span> <span class="nav-text">Fully-connected neural network</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Feed-forward"><span class="nav-number">3.3.</span> <span class="nav-text">Feed-forward</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Training"><span class="nav-number">3.4.</span> <span class="nav-text">Training</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Gradient-Descent"><span class="nav-number">3.5.</span> <span class="nav-text">Gradient Descent</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Backpropagation"><span class="nav-number">3.6.</span> <span class="nav-text">Backpropagation</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Outline-of-parallelization-strategies-for-CUDA-and-MPI"><span class="nav-number">4.</span> <span class="nav-text">Outline of parallelization strategies for CUDA and MPI</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CPlusPlus小砖家</span>

  
</div>










    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>


        







        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="true"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  

  

  

  
  
	<script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js">
	</script>
  
</body>
</html>
